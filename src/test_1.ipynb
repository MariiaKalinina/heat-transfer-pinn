{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549f92a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import torch \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Reproducibility\n",
    "# -----------------------------\n",
    "torch.manual_seed(0)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Heat flux function (same form, now fed with t in Myr)\n",
    "# -----------------------------\n",
    "def heat_flux(beta, t):\n",
    "    # Parameters (interpret in the same units as t; here t is in Myr)\n",
    "    a = 125\n",
    "    tau = 62.8     # if your physics expects tau in other units, rescale here\n",
    "    lam = 3.5\n",
    "    T1 = 1333\n",
    "    N = 100\n",
    "\n",
    "    T_sum = 0.0\n",
    "    for n in range(1, N+1):\n",
    "        Cn = beta/(n*np.pi) * np.sin(n*np.pi/beta) * np.exp(-(n**2)*t/tau)\n",
    "        T_sum += Cn\n",
    "    T_over_Tm = 0.8 * (1 + 2*T_sum)  # 0.8 ~ baseline scale\n",
    "\n",
    "    # Scaling kept from your snippet\n",
    "    return T_over_Tm * 1e-3 * 60 * 697\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Synthetic multi-well data (8 wells, geological time 0..260 Myr)\n",
    "# -----------------------------\n",
    "WELLS = 5\n",
    "N = 500                                 # time samples per well\n",
    "t_myr = np.linspace(0.0, 260.0, N)       # geological time axis (Myr)\n",
    "\n",
    "LITHO_NAMES = [\"Shale\", \"Chalk\", \"Limestone\", \"Anhydrite\", \"Quartzite\", \"Dolomite\"]\n",
    "LITHO_TO_INT = {name: i for i, name in enumerate(LITHO_NAMES)}\n",
    "\n",
    "rows, layer_rows = [], []\n",
    "\n",
    "for w in range(WELLS):\n",
    "    # Static per-well\n",
    "    litho_name = rng.choice(LITHO_NAMES)\n",
    "    litho = LITHO_TO_INT[litho_name]\n",
    "    porosity = rng.uniform(0.0, 0.7)\n",
    "    k = rng.uniform(1.0, 6.0)              # W/mK\n",
    "    swit = rng.uniform(-20.0, 2.0)         # °C\n",
    "    age = rng.uniform(0.0, 260.0)          # Myr\n",
    "\n",
    "    # Radiogenic heat (per-layer) -> aggregate totals\n",
    "    n_layers = rng.integers(2, 7)\n",
    "    rad_layers = rng.uniform(0.1, 4.0, n_layers)\n",
    "    rad_heat_total = float(rad_layers.sum())\n",
    "    rad_heat_mean  = float(rad_layers.mean())\n",
    "    for li, rh in enumerate(rad_layers):\n",
    "        layer_rows.append({\"well_id\": w, \"layer_id\": li, \"radiogenic_heat\": float(rh)})\n",
    "\n",
    "    # Target from heat_flux over geological time\n",
    "    beta = rng.uniform(1.5, 3.0)           # per-well control parameter\n",
    "    q_base = heat_flux(beta, t_myr)        # (N,)\n",
    "\n",
    "    # Small static effects to differentiate wells\n",
    "    q = (\n",
    "        q_base\n",
    "        + 0.05*(k - 3.5)\n",
    "        - 0.06*(porosity - 0.2)\n",
    "        + 0.005*(swit + 10.0)\n",
    "        + 0.0008*(age - 130.0)\n",
    "        + 0.02*(rad_heat_total - 8.0)\n",
    "        + rng.normal(0, 0.05, N)           # small noise\n",
    "    )\n",
    "\n",
    "    dfw = pd.DataFrame({\n",
    "        \"well_id\": w,\n",
    "        \"time_myr\": t_myr,\n",
    "        \"q\": q.astype(float),\n",
    "        \"lithology\": litho,\n",
    "        \"lithology_name\": litho_name,\n",
    "        \"thermal_conductivity\": k,\n",
    "        \"porosity\": porosity,\n",
    "        \"swit\": swit,\n",
    "        \"age\": age,\n",
    "        \"rad_heat_total\": rad_heat_total,\n",
    "        \"rad_heat_mean\": rad_heat_mean,\n",
    "        \"layers_count\": n_layers,\n",
    "    })\n",
    "    rows.append(dfw)\n",
    "\n",
    "df = pd.concat(rows).reset_index(drop=True).sort_values([\"well_id\",\"time_myr\"]).reset_index(drop=True)\n",
    "well_layers = pd.DataFrame(layer_rows).sort_values([\"well_id\", \"layer_id\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Columns config (no calendar/date features)\n",
    "# -----------------------------\n",
    "# Add normalized time as a dynamic feature so the model \"knows\" where it is on the Myr axis\n",
    "df[\"time_myr_norm\"] = (df[\"time_myr\"] - df[\"time_myr\"].min()) / (df[\"time_myr\"].max() - df[\"time_myr\"].min())\n",
    "\n",
    "TARGET_COL = \"q\"\n",
    "DYN_COLS = [\"q\", \"time_myr_norm\"]                    # autoregressive + time position\n",
    "STATIC_CONT_COLS = [\"thermal_conductivity\",\"porosity\",\"swit\",\"age\",\"rad_heat_total\"]\n",
    "STATIC_CAT_COLS  = [\"lithology\"]\n",
    "USE_WELL_ID_EMB = True\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Per-well chronological split (by geological time)\n",
    "# -----------------------------\n",
    "TRAIN_FRAC, VAL_FRAC = 0.70, 0.15\n",
    "def split_per_well(df_all):\n",
    "    parts = []\n",
    "    for wid, g in df_all.groupby(\"well_id\", sort=False):\n",
    "        g = g.sort_values(\"time_myr\").copy()\n",
    "        n = len(g)\n",
    "        n_tr = int(n*TRAIN_FRAC)\n",
    "        n_va = int(n*(TRAIN_FRAC+VAL_FRAC))\n",
    "        g.loc[g.index[:n_tr], \"split\"] = \"train\"\n",
    "        g.loc[g.index[n_tr:n_va], \"split\"] = \"val\"\n",
    "        g.loc[g.index[n_va:], \"split\"] = \"test\"\n",
    "        parts.append(g)\n",
    "    return pd.concat(parts).reset_index(drop=True)\n",
    "\n",
    "df_splits = split_per_well(df)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Normalize (fit on train only)\n",
    "# -----------------------------\n",
    "dyn_mean = df_splits[df_splits[\"split\"]==\"train\"][DYN_COLS].mean()\n",
    "dyn_std  = df_splits[df_splits[\"split\"]==\"train\"][DYN_COLS].std().replace(0,1.0).fillna(1.0)\n",
    "stat_mean = df_splits[df_splits[\"split\"]==\"train\"][STATIC_CONT_COLS].mean()\n",
    "stat_std  = df_splits[df_splits[\"split\"]==\"train\"][STATIC_CONT_COLS].std().replace(0,1.0).fillna(1.0)\n",
    "\n",
    "df_norm = df_splits.copy()\n",
    "df_norm[DYN_COLS] = (df_norm[DYN_COLS]-dyn_mean)/dyn_std\n",
    "df_norm[STATIC_CONT_COLS] = (df_norm[STATIC_CONT_COLS]-stat_mean)/stat_std\n",
    "\n",
    "num_wells = df_norm[\"well_id\"].nunique()\n",
    "cat_card  = {c: int(df_norm[c].max())+1 for c in STATIC_CAT_COLS}\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Dataset (sequence windows; sorted by time_myr)\n",
    "# -----------------------------\n",
    "WIN = 168\n",
    "HORIZON = 1\n",
    "\n",
    "class MultiWellTS(torch.utils.data.Dataset):\n",
    "    def __init__(self, df_all, win, horizon, target_split: str):\n",
    "        self.samples = []\n",
    "        self.win, self.h = win, horizon\n",
    "        assert target_split in {\"train\",\"val\",\"test\"}\n",
    "        for w, g in df_all.groupby(\"well_id\", sort=False):\n",
    "            g = g.sort_values(\"time_myr\").copy()\n",
    "            Xdyn = g[DYN_COLS].to_numpy(np.float32)\n",
    "            y    = g[TARGET_COL].to_numpy(np.float32)\n",
    "            tmyr = g[\"time_myr\"].to_numpy(np.float32)\n",
    "            scont = g[STATIC_CONT_COLS].iloc[0].to_numpy(np.float32)\n",
    "            scat  = {c:int(g[c].iloc[0]) for c in STATIC_CAT_COLS}\n",
    "            wid   = int(w)\n",
    "            mask_target = (g[\"split\"].values == target_split)\n",
    "            for j in range(self.win, len(g)-self.h+1):\n",
    "                if not mask_target[j]:\n",
    "                    continue\n",
    "                x_win = Xdyn[j-self.win:j]\n",
    "                y_next = y[j:j+self.h]\n",
    "                if np.isnan(x_win).any() or np.isnan(y_next).any():\n",
    "                    continue\n",
    "                t_val = tmyr[j]  # keep the time (Myr) of the target\n",
    "                self.samples.append((x_win, y_next, scont, scat, wid, t_val))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, scont, scat, wid, t_val = self.samples[idx]\n",
    "        return (torch.from_numpy(x),\n",
    "                torch.from_numpy(y),\n",
    "                torch.from_numpy(scont),\n",
    "                torch.tensor([scat[c] for c in STATIC_CAT_COLS], dtype=torch.long),\n",
    "                torch.tensor(wid, dtype=torch.long),\n",
    "                torch.tensor(t_val, dtype=torch.float32))  # time in Myr\n",
    "\n",
    "train_ds = MultiWellTS(df_norm, WIN, HORIZON, target_split=\"train\")\n",
    "val_ds   = MultiWellTS(df_norm, WIN, HORIZON, target_split=\"val\")\n",
    "test_ds  = MultiWellTS(df_norm, WIN, HORIZON, target_split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Windows per split -> train: {len(train_ds)}, val: {len(val_ds)}, test: {len(test_ds)}\")\n",
    "assert len(train_ds)>0 and len(val_ds)>0 and len(test_ds)>0\n",
    "\n",
    "F_DYN = len(DYN_COLS)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Model: GRU + static conditioning\n",
    "# -----------------------------\n",
    "class GRUWithStatics(nn.Module):\n",
    "    def __init__(self, f_dyn, hidden=192, layers=1, dropout=0.1,\n",
    "                 cat_card=None, cat_emb_dim=8, static_cont_dim=2,\n",
    "                 use_well_emb=True, num_wells=1, well_emb_dim=8, horizon=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(f_dyn, hidden, num_layers=layers, batch_first=True,\n",
    "                          dropout=dropout if layers>1 else 0.0)\n",
    "\n",
    "        self.cat_embs = nn.ModuleDict()\n",
    "        total_cat_dim = 0\n",
    "        if cat_card:\n",
    "            for name, K in cat_card.items():\n",
    "                self.cat_embs[name] = nn.Embedding(K, cat_emb_dim)\n",
    "            total_cat_dim = cat_emb_dim * len(cat_card)\n",
    "\n",
    "        self.use_well_emb = use_well_emb\n",
    "        self.well_emb = nn.Embedding(num_wells, well_emb_dim) if use_well_emb else None\n",
    "\n",
    "        static_in = static_cont_dim + total_cat_dim + (well_emb_dim if use_well_emb else 0)\n",
    "        self.static_mlp = nn.Sequential(\n",
    "            nn.Linear(static_in, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.head = nn.Linear(hidden + 64, horizon)\n",
    "\n",
    "    def forward(self, x_dyn, x_stat_cont, x_stat_cat, well_id):\n",
    "        h_seq, _ = self.gru(x_dyn)           # (B, T, H)\n",
    "        h_last = h_seq[:, -1, :]             # (B, H)\n",
    "\n",
    "        cat_vecs = []\n",
    "        if self.cat_embs:\n",
    "            for i, name in enumerate(self.cat_embs.keys()):\n",
    "                cat_vecs.append(self.cat_embs[name](x_stat_cat[:, i]))\n",
    "        cat_vec = torch.cat(cat_vecs, dim=-1) if cat_vecs else None\n",
    "        well_vec = self.well_emb(well_id) if self.use_well_emb else None\n",
    "\n",
    "        parts = [x_stat_cont]\n",
    "        if cat_vec is not None: parts.append(cat_vec)\n",
    "        if well_vec is not None: parts.append(well_vec)\n",
    "        static_all = torch.cat(parts, dim=-1)\n",
    "        static_feat = self.static_mlp(static_all)\n",
    "\n",
    "        yhat = self.head(torch.cat([h_last, static_feat], dim=-1))\n",
    "        return yhat\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = GRUWithStatics(\n",
    "    f_dyn=F_DYN, hidden=192, layers=1, dropout=0.1,\n",
    "    cat_card=cat_card, cat_emb_dim=8, static_cont_dim=len(STATIC_CONT_COLS),\n",
    "    use_well_emb=USE_WELL_ID_EMB, num_wells=num_wells, well_emb_dim=8, horizon=1\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Train + simple early stop\n",
    "# -----------------------------\n",
    "train_hist, val_hist = [], []\n",
    "best_val = 1e9; best = None; patience=5; noimp=0\n",
    "for epoch in range(1, 31):\n",
    "    model.train(); tr_losses=[]\n",
    "    for xb, yb, scont, scat, wid, _t in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        scont, scat, wid = scont.to(device), scat.to(device), wid.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred = model(xb, scont, scat, wid)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        tr_losses.append(loss.item())\n",
    "    model.eval(); va_losses=[]\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, scont, scat, wid, _t in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            scont, scat, wid = scont.to(device), scat.to(device), wid.to(device)\n",
    "            va_losses.append(loss_fn(model(xb, scont, scat, wid), yb).item())\n",
    "    tr, va = float(np.mean(tr_losses)), float(np.mean(va_losses))\n",
    "    train_hist.append(tr); val_hist.append(va)\n",
    "    print(f\"Epoch {epoch:02d} | train MAE={tr:.4f} | val MAE={va:.4f}\")\n",
    "    if va + 1e-6 < best_val:\n",
    "        best_val = va; best = {k:v.cpu().clone() for k,v in model.state_dict().items()}; noimp=0\n",
    "    else:\n",
    "        noimp += 1\n",
    "        if noimp >= patience:\n",
    "            print(\"Early stopping.\"); break\n",
    "if best: model.load_state_dict({k:v.to(device) for k,v in best.items()})\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Test (collect preds + metadata)\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "preds, truths, well_ids, t_list = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb, scont, scat, wid, t_val in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        scont, scat, wid = scont.to(device), scat.to(device), wid.to(device)\n",
    "        p = model(xb, scont, scat, wid)\n",
    "        preds.append(p.cpu().numpy())\n",
    "        truths.append(yb.cpu().numpy())\n",
    "        well_ids.append(wid.cpu().numpy())\n",
    "        t_list.append(t_val.cpu().numpy())\n",
    "\n",
    "preds    = np.vstack(preds).squeeze(-1)\n",
    "truths   = np.vstack(truths).squeeze(-1)\n",
    "well_ids = np.concatenate(well_ids)\n",
    "tvals    = np.concatenate(t_list)   # time in Myr (float)\n",
    "\n",
    "mae = np.mean(np.abs(preds-truths))\n",
    "rmse = np.sqrt(np.mean((preds-truths)**2))\n",
    "print(f\"Test MAE={mae:.3f} | RMSE={rmse:.3f}  (normalized units)\")\n",
    "\n",
    "# To express in original q-units, multiply by training std of q:\n",
    "print(\"Approx in original q-units:\",\n",
    "      f\"MAE≈{mae*float(dyn_std['q']):.3f}, RMSE≈{rmse*float(dyn_std['q']):.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 10) Visualizations (geologic time)\n",
    "# -----------------------------\n",
    "# (A) Train vs Val MAE\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.plot(train_hist, label=\"train MAE\")\n",
    "plt.plot(val_hist, label=\"val MAE\")\n",
    "plt.title(\"Training history\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# (B) Time series (test) for a chosen well (tail) vs Myr\n",
    "well_to_plot = int(pd.Series(well_ids).mode()[0])\n",
    "mask = (well_ids == well_to_plot)\n",
    "df_plot = pd.DataFrame({\n",
    "    \"time_myr\": tvals[mask],\n",
    "    \"y_true\": truths[mask],\n",
    "    \"y_pred\": preds[mask],\n",
    "}).sort_values(\"time_myr\")\n",
    "tail = df_plot.tail(1000)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(tail[\"time_myr\"], tail[\"y_true\"], label=\"true\")\n",
    "plt.plot(tail[\"time_myr\"], tail[\"y_pred\"], label=\"pred\")\n",
    "plt.title(f\"Test predictions vs truth (well {well_to_plot}, tail)\")\n",
    "plt.xlabel(\"Time (Myr)\")\n",
    "plt.ylabel(\"Normalized q\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# (C) Scatter: True vs Pred\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(truths, preds, s=10, alpha=0.5)\n",
    "minv, maxv = float(min(truths.min(), preds.min())), float(max(truths.max(), preds.max()))\n",
    "plt.plot([minv, maxv], [minv, maxv])\n",
    "plt.title(\"Predicted vs True (test)\")\n",
    "plt.xlabel(\"True\"); plt.ylabel(\"Predicted\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# (D) Residual histogram\n",
    "res = preds - truths\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.hist(res, bins=40)\n",
    "plt.title(\"Residuals (pred - true)\")\n",
    "plt.xlabel(\"Residual\"); plt.ylabel(\"Count\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# (E) Per-well MAE bar plot\n",
    "per_well = []\n",
    "for w in np.unique(well_ids):\n",
    "    m = (well_ids==w)\n",
    "    per_well.append((int(w), float(np.mean(np.abs(preds[m]-truths[m])))))\n",
    "per_well = pd.DataFrame(per_well, columns=[\"well_id\",\"MAE\"]).sort_values(\"well_id\")\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(per_well[\"well_id\"].astype(str), per_well[\"MAE\"])\n",
    "plt.title(\"Per-well MAE (test)\")\n",
    "plt.xlabel(\"well_id\"); plt.ylabel(\"MAE (normalized)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a295de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
